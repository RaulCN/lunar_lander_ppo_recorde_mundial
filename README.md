<div align="center">

# üöÄ Lunar Lander PPO ‚Äî Curr√≠culo Adaptativo üèÜ  
### Recorde Mundial no LunarLander-v3

[![Python](https://img.shields.io/badge/Python-3.10%2B-3776AB?logo=python&logoColor=white)](https://www.python.org/)
[![Stable-Baselines3](https://img.shields.io/badge/Stable--Baselines3-PPO-FF6F00)](https://stable-baselines3.readthedocs.io/)
[![Gymnasium](https://img.shields.io/badge/Gymnasium-LunarLander--v3-009688)](https://gymnasium.farama.org/)
[![Hugging Face Model](https://img.shields.io/badge/HuggingFace-Modelo-FCC624?logo=huggingface)](https://huggingface.co/rautopia/ppo-lunar-lander-v3-max322)
[![Hugging Face Demo](https://img.shields.io/badge/HuggingFace-Demo-blue?logo=huggingface)](https://huggingface.co/spaces/rautopia/lunar-lander-ppo-demo-322)
[![License: MIT](https://img.shields.io/badge/License-MIT-4CAF50.svg)](LICENSE)  
[![Status](https://img.shields.io/badge/Status-Ativo-brightgreen)](#)
[![Stars](https://img.shields.io/github/stars/RaulCN/lunar_lander_ppo_recorde_mundial?style=social)](https://github.com/RaulCN/lunar_lander_ppo_recorde_mundial/stargazers)
[![Downloads](https://img.shields.io/github/downloads/RaulCN/lunar_lander_ppo_recorde_mundial/total?label=Downloads)](https://github.com/RaulCN/lunar_lander_ppo_recorde_mundial/releases)

---

üéØ **Agente PPO com curr√≠culo adaptativo** que alcan√ßa desempenho de ponta no desafio `LunarLander-v3`,  
com pousos consistentes, robustos e otimizados para diferentes n√≠veis de dificuldade.

---

<img src="gif/seed5.gif" alt="Demonstra√ß√£o do agente Lunar Lander PPO" width="650"/>

</div>


Este projeto implementa um agente de aprendizado por refor√ßo profundo (Deep Reinforcement Learning) utilizando o algoritmo **PPO (Proximal Policy Optimization)** para controlar uma nave no ambiente `LunarLander-v3`. O agente √© treinado com m√∫ltiplas etapas de dificuldade crescente por meio de um curr√≠culo adaptativo, permitindo pousos suaves e eficientes em cen√°rios cada vez mais desafiadores.

## Estrutura do Projeto

- `treinamento.py`: Script de treinamento com curr√≠culo adaptativo e progress√£o din√¢mica de dificuldade.
- `agente.py`: Script de avalia√ß√£o e teste do modelo treinado, com visualiza√ß√£o, an√°lise estat√≠stica e gera√ß√£o de gr√°ficos.

## Caracter√≠sticas T√©cnicas

### Aprendizado com Curr√≠culo Adaptativo

O script de treinamento aplica quatro fases distintas:
1. **Fase Inicial**: Ambiente padr√£o com semente fixa.
2. **Generaliza√ß√£o**: Ativa√ß√£o de sementes aleat√≥rias ao atingir recompensa m√©dia ‚â• 200.
3. **Modo Dif√≠cil**: Introdu√ß√£o de instabilidades f√≠sicas quando a m√©dia atinge ‚â• 240.
4. **Refino**: Penalidade por n√∫mero de passos ativada ao atingir m√©dia ‚â• 260.

### Arquitetura do Modelo

```python
ActorCriticPolicy(
  MlpExtractor:
    policy_net:  [8 ‚Üí 64 ‚Üí 64]
    value_net:   [8 ‚Üí 64 ‚Üí 64]
)
# Total de par√¢metros: 9.797
```

## Resultados

### Avalia√ß√£o Final (50 epis√≥dios)

- **Taxa de sucesso:** 94.0% (47/50)
- **Recompensa m√©dia:** 274.70 ¬± 51.71
- **Recompensa m√°xima:** 322.00
- **Pousos suaves:** 50/50
- **Tempo m√©dio por epis√≥dio:** 5.54s
- **Velocidade vertical m√©dia:** 0.00
- **√Çngulo m√©dio:** 0.01 rad

Gr√°fico de desempenho salvo como `performance_graph.png`.

### Dados do Treinamento Final

- **Timesteps totais:** 12.000.000
- **Recompensa m√©dia (√∫ltimos 10 epis√≥dios):** 288.83
- **Recompensa avaliada:** 262.77 ¬± 36.83
- **Explained Variance:** 0.998
- **Entropy Loss:** -0.228
- **FPS:** 28

## Execu√ß√£o

### Requisitos

- Python 3.10+
- stable-baselines3
- gymnasium
- matplotlib
- numpy

### Treinar o modelo

```bash
python treinamento.py
```

### Avaliar o agente

```bash
python agente.py
```

## Acesso ao Modelo

Os pesos treinados do agente est√£o dispon√≠veis no Hugging Face:

**Hugging Face Hub:**  
https://huggingface.co/rautopia/ppo-lunar-lander-v3-max322

## Autor

**Raul Campos Nascimento**  
Email: rautopiaa@gmail.com
